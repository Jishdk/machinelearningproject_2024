{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dutch Housing Market Price Prediction - Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 5555 houses and 16 features\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure for processed data and results\n",
    "preprocessed_dir = '../preprocessed_data'\n",
    "results_dir = '../results'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [preprocessed_dir, results_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Load raw housing data\n",
    "df_preprocessing = pd.read_csv('../data/raw_data.csv')\n",
    "print(f\"Loaded dataset with {len(df_preprocessing)} houses and {len(df_preprocessing.columns)} features\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature cleaning...\n",
      "Cleaned data: removed 13 rows with invalid prices\n"
     ]
    }
   ],
   "source": [
    "def clean_price(price):\n",
    "    \"\"\"Convert Dutch price notation to float.\n",
    "    Example: '€ 525.000' -> 525000.0\n",
    "    \"\"\"\n",
    "    if isinstance(price, str):\n",
    "        price = price.replace('€', '').replace(' ', '')\n",
    "        if ',' in price:\n",
    "            price = price.replace('.', '').replace(',', '.')\n",
    "        else:\n",
    "            price = price.replace('.', '')\n",
    "        try:\n",
    "            return float(price)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "def clean_size(size):\n",
    "    \"\"\"Convert size with unit to float.\n",
    "    Example: '251 m²' -> 251.0\n",
    "    \"\"\"\n",
    "    if isinstance(size, str):\n",
    "        size = size.replace('m²', '').strip()\n",
    "        try:\n",
    "            return float(size)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Clean and preprocess features\n",
    "print(\"Starting feature cleaning...\")\n",
    "initial_count = len(df_preprocessing)\n",
    "\n",
    "# Clean numeric features\n",
    "df_preprocessing['Price'] = df_preprocessing['Price'].apply(clean_price)\n",
    "df_preprocessing['Living space size (m2)'] = df_preprocessing['Living space size (m2)'].apply(clean_size)\n",
    "df_preprocessing['Lot size (m2)'] = df_preprocessing['Lot size (m2)'].apply(clean_size)\n",
    "df_preprocessing['Build year'] = pd.to_numeric(df_preprocessing['Build year'], errors='coerce')\n",
    "\n",
    "# Simplify house type\n",
    "df_preprocessing['House type'] = df_preprocessing['House type'].apply(\n",
    "    lambda x: x.split(',')[0] if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Remove rows with missing prices (our target variable)\n",
    "df_preprocessing = df_preprocessing.dropna(subset=['Price'])\n",
    "\n",
    "print(f\"Cleaned data: removed {initial_count - len(df_preprocessing)} rows with invalid prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for house price prediction\n",
    "selected_features = [\n",
    "    'Price',                    # Target variable\n",
    "    'Living space size (m2)',   # Key numeric features\n",
    "    'Lot size (m2)',\n",
    "    'Build year',\n",
    "    'House type',               # Important categorical features\n",
    "    'City',\n",
    "    'Energy label'\n",
    "]\n",
    "\n",
    "# Create working dataset with selected features\n",
    "df_selected = df_preprocessing[selected_features].copy()\n",
    "\n",
    "# Handle any remaining missing values\n",
    "numeric_features = ['Living space size (m2)', 'Lot size (m2)', 'Build year']\n",
    "categorical_features = ['House type', 'City', 'Energy label']\n",
    "\n",
    "# Fill missing numeric values with median (a common strategy for housing data)\n",
    "for feature in numeric_features:\n",
    "    median_value = df_selected[feature].median()\n",
    "    df_selected[feature].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled {df_selected[feature].isnull().sum()} missing values in {feature}\")\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "for feature in categorical_features:\n",
    "    mode_value = df_selected[feature].mode()[0]\n",
    "    df_selected[feature].fillna(mode_value, inplace=True)\n",
    "    print(f\"Filled {df_selected[feature].isnull().sum()} missing values in {feature}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "# One-hot encode house types (since types aren't ordinal)\n",
    "df_selected = pd.get_dummies(df_selected, columns=['House type'], drop_first=True)\n",
    "\n",
    "# Label encode city and energy label\n",
    "label_encoders = {}\n",
    "for feature in ['City', 'Energy label']:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    df_selected[feature] = label_encoders[feature].fit_transform(df_selected[feature])\n",
    "    print(f\"Encoded {feature} into {df_selected[feature].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_selected.drop('Price', axis=1)\n",
    "y = df_selected['Price']\n",
    "\n",
    "# Split data into train, validation, and test sets (60/20/20)\n",
    "print(\"\\nSplitting data into train, validation, and test sets...\")\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale numeric features using StandardScaler\n",
    "print(\"Scaling numeric features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_val[numeric_features] = scaler.transform(X_val[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Quick verification of scaled features\n",
    "print(\"\\nVerifying scaling results (mean should be ~0, std should be ~1):\")\n",
    "for feature in numeric_features:\n",
    "    mean = X_train[feature].mean()\n",
    "    std = X_train[feature].std()\n",
    "    print(f\"{feature}: mean={mean:.3f}, std={std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete!\n",
      "Train set size: 3324\n",
      "Validation set size: 1109\n",
      "Test set size: 1109\n"
     ]
    }
   ],
   "source": [
    "# Save processed data for later use\n",
    "X_train.to_csv('../preprocessed_data/X_train.csv', index=False)\n",
    "X_val.to_csv('../preprocessed_data/X_val.csv', index=False)\n",
    "X_test.to_csv('../preprocessed_data/X_test.csv', index=False)\n",
    "y_train.to_csv('../preprocessed_data/y_train.csv', index=False)\n",
    "y_val.to_csv('../preprocessed_data/y_val.csv', index=False)\n",
    "y_test.to_csv('../preprocessed_data/y_test.csv', index=False)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
