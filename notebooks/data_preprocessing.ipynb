{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dutch Housing Market Price Prediction - Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 5555 houses and 16 features\n"
     ]
    }
   ],
   "source": [
    "# Create directory structure for processed data and results\n",
    "preprocessed_dir = '../preprocessed_data'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Load raw housing data\n",
    "df_preprocessing = pd.read_csv('../data/raw_data.csv')\n",
    "print(f\"Loaded dataset with {len(df_preprocessing)} houses and {len(df_preprocessing.columns)} features\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature cleaning...\n",
      "Cleaned data: removed 13 rows with invalid prices\n"
     ]
    }
   ],
   "source": [
    "def clean_price(price):\n",
    "    \"\"\"Convert Dutch price notation to float.\n",
    "    Example: '€ 525.000' -> 525000.0\n",
    "    \"\"\"\n",
    "    if isinstance(price, str):\n",
    "        price = price.replace('€', '').replace(' ', '')\n",
    "        if ',' in price:\n",
    "            price = price.replace('.', '').replace(',', '.')\n",
    "        else:\n",
    "            price = price.replace('.', '')\n",
    "        try:\n",
    "            return float(price)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "def clean_size(size):\n",
    "    \"\"\"Convert size with unit to float.\n",
    "    Example: '251 m²' -> 251.0\n",
    "    \"\"\"\n",
    "    if isinstance(size, str):\n",
    "        size = size.replace('m²', '').strip()\n",
    "        try:\n",
    "            return float(size)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Clean and preprocess features\n",
    "print(\"Starting feature cleaning...\")\n",
    "initial_count = len(df_preprocessing)\n",
    "\n",
    "# Clean numeric features\n",
    "df_preprocessing['Price'] = df_preprocessing['Price'].apply(clean_price)\n",
    "df_preprocessing['Living space size (m2)'] = df_preprocessing['Living space size (m2)'].apply(clean_size)\n",
    "df_preprocessing['Lot size (m2)'] = df_preprocessing['Lot size (m2)'].apply(clean_size)\n",
    "df_preprocessing['Build year'] = pd.to_numeric(df_preprocessing['Build year'], errors='coerce')\n",
    "\n",
    "# Simplify house type\n",
    "df_preprocessing['House type'] = df_preprocessing['House type'].apply(\n",
    "    lambda x: x.split(',')[0] if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Remove rows with missing prices (our target variable)\n",
    "df_preprocessing = df_preprocessing.dropna(subset=['Price'])\n",
    "\n",
    "print(f\"Cleaned data: removed {initial_count - len(df_preprocessing)} rows with invalid prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 0 missing values in Living space size (m2)\n",
      "Filled 0 missing values in Lot size (m2)\n",
      "Filled 0 missing values in Build year\n",
      "Filled 0 missing values in House type\n",
      "Filled 0 missing values in City\n",
      "Filled 0 missing values in Energy label\n",
      "\n",
      "Encoding categorical variables...\n",
      "Encoded City into 1071 unique values\n",
      "Encoded Energy label into 12 unique values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90670/2815170056.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_selected[feature].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_90670/2815170056.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_selected[feature].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_90670/2815170056.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_selected[feature].fillna(median_value, inplace=True)\n",
      "/tmp/ipykernel_90670/2815170056.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_selected[feature].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Select relevant features for house price prediction\n",
    "selected_features = [\n",
    "    'Price',                    # Target variable\n",
    "    'Living space size (m2)',   # Key numeric features\n",
    "    'Lot size (m2)',\n",
    "    'Build year',\n",
    "    'House type',               # Important categorical features\n",
    "    'City',\n",
    "    'Energy label'\n",
    "]\n",
    "\n",
    "# Create working dataset with selected features\n",
    "df_selected = df_preprocessing[selected_features].copy()\n",
    "\n",
    "# Handle any remaining missing values\n",
    "numeric_features = ['Living space size (m2)', 'Lot size (m2)', 'Build year']\n",
    "categorical_features = ['House type', 'City', 'Energy label']\n",
    "\n",
    "# Fill missing numeric values with median (a common strategy for housing data)\n",
    "for feature in numeric_features:\n",
    "    median_value = df_selected[feature].median()\n",
    "    df_selected[feature].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled {df_selected[feature].isnull().sum()} missing values in {feature}\")\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "for feature in categorical_features:\n",
    "    mode_value = df_selected[feature].mode()[0]\n",
    "    df_selected[feature].fillna(mode_value, inplace=True)\n",
    "    print(f\"Filled {df_selected[feature].isnull().sum()} missing values in {feature}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "# One-hot encode house types (since types aren't ordinal)\n",
    "df_selected = pd.get_dummies(df_selected, columns=['House type'], drop_first=True)\n",
    "\n",
    "# Label encode city and energy label\n",
    "label_encoders = {}\n",
    "for feature in ['City', 'Energy label']:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    df_selected[feature] = label_encoders[feature].fit_transform(df_selected[feature])\n",
    "    print(f\"Encoded {feature} into {df_selected[feature].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into train, validation, and test sets...\n",
      "Scaling numeric features...\n",
      "\n",
      "Verifying scaling results (mean should be ~0, std should be ~1):\n",
      "Living space size (m2): mean=0.000, std=1.000\n",
      "Lot size (m2): mean=-0.000, std=1.000\n",
      "Build year: mean=0.000, std=1.000\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = df_selected.drop('Price', axis=1)\n",
    "y = df_selected['Price']\n",
    "\n",
    "# Split data into train, validation, and test sets (60/20/20)\n",
    "print(\"\\nSplitting data into train, validation, and test sets...\")\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale numeric features using StandardScaler\n",
    "print(\"Scaling numeric features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_val[numeric_features] = scaler.transform(X_val[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "# Quick verification of scaled features\n",
    "print(\"\\nVerifying scaling results (mean should be ~0, std should be ~1):\")\n",
    "for feature in numeric_features:\n",
    "    mean = X_train[feature].mean()\n",
    "    std = X_train[feature].std()\n",
    "    print(f\"{feature}: mean={mean:.3f}, std={std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving processed datasets...\n",
      "\n",
      "Preprocessing Summary:\n",
      "Training set: 3324 samples\n",
      "Validation set: 1109 samples\n",
      "Test set: 1109 samples\n",
      "Total features after encoding: 12\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets\n",
    "print(\"\\nSaving processed datasets...\")\n",
    "\n",
    "# Create paths for saving\n",
    "preprocessed_paths = {\n",
    "    'X_train': '../preprocessed_data/X_train.csv',\n",
    "    'X_val': '../preprocessed_data/X_val.csv',\n",
    "    'X_test': '../preprocessed_data/X_test.csv',\n",
    "    'y_train': '../preprocessed_data/y_train.csv',\n",
    "    'y_val': '../preprocessed_data/y_val.csv',\n",
    "    'y_test': '../preprocessed_data/y_test.csv'\n",
    "}\n",
    "\n",
    "# Save all datasets\n",
    "for name, path in preprocessed_paths.items():\n",
    "    if name.startswith('X'):\n",
    "        eval(name).to_csv(path, index=False)\n",
    "    else:\n",
    "        eval(name).to_csv(path, index=False)\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(\"\\nPreprocessing Summary:\")\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Total features after encoding: {len(X_train.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
